{
 "metadata": {
  "name": "",
  "signature": "sha256:dafa097cbd9b5edad811e06c17107b83b2a08c1604c6dd03ac8a799b8b127421"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Measuring prediction performance"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Using the K-neighbors classifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we'll continue to look at the digits data, but we'll switch to the\n",
      "K-Neighbors classifier.  The K-neighbors classifier is an instance-based\n",
      "classifier.  The K-neighbors classifier predicts the label of\n",
      "an unknown point based on the labels of the *K* nearest points in the\n",
      "parameter space."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the data\n",
      "from sklearn.datasets import load_digits\n",
      "digits = load_digits()\n",
      "X = digits.data\n",
      "y = digits.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instantiate and train the classifier\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "clf = KNeighborsClassifier(n_neighbors=1)\n",
      "clf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Check the results using metrics\n",
      "from sklearn import metrics\n",
      "y_pred = clf.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(metrics.confusion_matrix(y_pred, y))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Apparently, we've found a perfect classifier!  But this is misleading\n",
      "for the reasons we saw before: the classifier essentially \"memorizes\"\n",
      "all the samples it has already seen.  To really test how well this\n",
      "algorithm does, we need to try some samples it *hasn't* yet seen.\n",
      "\n",
      "This problem can also occur with regression models. In the following we fit an other instance-based model named \"decision tree\" to the Boston Housing price dataset we introduced previously:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from matplotlib import pyplot as plt\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_boston\n",
      "from sklearn.tree import DecisionTreeRegressor\n",
      "\n",
      "data = load_boston()\n",
      "clf = DecisionTreeRegressor().fit(data.data, data.target)\n",
      "predicted = clf.predict(data.data)\n",
      "expected = data.target\n",
      "\n",
      "plt.scatter(expected, predicted)\n",
      "plt.plot([0, 50], [0, 50], '--k')\n",
      "plt.axis('tight')\n",
      "plt.xlabel('True price ($1000s)')\n",
      "plt.ylabel('Predicted price ($1000s)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here again the predictions are seemingly perfect as the model was able to perfectly memorize the training set."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "A Better Approach: Using a validation set"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Learning the parameters of a prediction function and testing it on the\n",
      "same data is a methodological mistake: a model that would just repeat\n",
      "the labels of the samples that it has just seen would have a perfect\n",
      "score but would fail to predict anything useful on yet-unseen data.\n",
      "\n",
      "To avoid over-fitting, we have to define two different sets:\n",
      "\n",
      "- a training set X_train, y_train which is used for learning the parameters of a predictive model\n",
      "- a testing set X_test, y_test which is used for evaluating the fitted predictive model\n",
      "\n",
      "In scikit-learn such a random split can be quickly computed with the\n",
      "`train_test_split` helper function.  It can be used this way:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "X = digits.data\n",
      "y = digits.target\n",
      "\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.25, random_state=0)\n",
      "\n",
      "print(\"%r, %r, %r\" % (X.shape, X_train.shape, X_test.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we train on the training data, and test on the testing data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = KNeighborsClassifier(n_neighbors=1).fit(X_train, y_train)\n",
      "y_pred = clf.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(metrics.confusion_matrix(y_test, y_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(metrics.classification_report(y_test, y_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The averaged f1-score is often used as a convenient measure of the\n",
      "overall performance of an algorithm.  It appears in the bottom row\n",
      "of the classification report; it can also be accessed directly:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metrics.f1_score(y_test, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The over-fitting we saw previously can be quantified by computing the\n",
      "f1-score on the training data itself:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metrics.f1_score(y_train, clf.predict(X_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Regression metrics** In the case of regression models, we need to use different metrics, such as explained variance."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Application: Model Selection via Validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the previous notebook, we saw Gaussian Naive Bayes classification of the digits.\n",
      "Here we saw K-neighbors classification of the digits.  We've also seen support vector\n",
      "machine classification of digits.  Now that we have these\n",
      "validation tools in place, we can ask quantitatively which of the three estimators\n",
      "works best for the digits dataset.\n",
      "\n",
      "- With the default hyper-parameters for each estimator, which gives the best f1 score\n",
      "  on the **validation set**?  Recall that hyperparameters are the parameters set when\n",
      "  you instantiate the classifier: for example, the ``n_neighbors`` in\n",
      "\n",
      "          clf = KNeighborsClassifier(n_neighbors=1)\n",
      "\n",
      "- For each classifier, which value for the hyperparameters gives the best results for\n",
      "  the digits data?  For ``LinearSVC``, use ``loss='l2'`` and ``loss='l1'``.  For\n",
      "  ``KNeighborsClassifier`` we use ``n_neighbors`` between 1 and 10.  Note that ``GaussianNB``\n",
      "  does not have any adjustable hyperparameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "import warnings  # suppress warnings from older versions of KNeighbors\n",
      "warnings.filterwarnings('ignore', message='kneighbors*')\n",
      "\n",
      "X = digits.data\n",
      "y = digits.target\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.25, random_state=0)\n",
      "\n",
      "for Model in [LinearSVC, GaussianNB, KNeighborsClassifier]:\n",
      "    clf = Model().fit(X_train, y_train)\n",
      "    y_pred = clf.predict(X_test)\n",
      "    print Model.__name__, metrics.f1_score(y_test, y_pred)\n",
      "    \n",
      "print '------------------'\n",
      "\n",
      "# test SVC loss\n",
      "for loss in ['l1', 'l2']:\n",
      "    clf = LinearSVC(loss=loss).fit(X_train, y_train)\n",
      "    y_pred = clf.predict(X_test)\n",
      "    print \"LinearSVC(loss='{0}')\".format(loss), metrics.f1_score(y_test, y_pred)\n",
      "    \n",
      "print '-------------------'\n",
      "    \n",
      "# test K-neighbors\n",
      "for n_neighbors in range(1, 11):\n",
      "    clf = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X_train, y_train)\n",
      "    y_pred = clf.predict(X_test)\n",
      "    print \"KNeighbors(n_neighbors={0})\".format(n_neighbors), metrics.f1_score(y_test, y_pred)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}